app:
  name: vit-ray

llm:
  serve_config:
    model: /data/yi-34b  # name / path
    download_dir: null # path to model
    load_format: safetensors  # format of model {auto, pt, dummy, safetensors}
    dtype: float16  # data type {auto, float32, float16, bfloat16}
    max_model_len: 2048  # max length of model
    worker_use_ray: false  # use ray for worker
    pipeline_parallel_size: 1  # size of pipeline parallel
    tensor_parallel_size: 1  # size of tensor parallel
    engine_use_ray: true  # use ray for engine
    # gpu_memory_utilization: 0.95  # gpu memory utilization
    enforce_eager: true

emb:
  serve_config:
    model_name: BAAI/bge-large-en-v1.5

loggers:  
  file:
    dir: /app/logs/
  console:
    rich: true
  
    
